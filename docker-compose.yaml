
services:
  # POSTGRESQL
  pgvector:
    image: pgvector/pgvector:0.8.0-pg17
    container_name: pgvector
    ports:
      - "5400:5432"
    volumes: 
      - pgvector:/var/lib/postgresql/data
    env_file:
      - ./env/.env.postgres
    networks:
      - backend
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s

  # LLM/EMBEDDINGS ===
  ollama:
    image: ollama/ollama
    container_name: rag_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - backend
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # PHOENIX FOR OBSERVABILITY
  phoenix:
    image: arizephoenix/phoenix:latest
    container_name: rag_phoenix
    ports:
      - "6006:6006"
    environment:
      - PHOENIX_SQL_DATABASE_URL=sqlite:///tmp/phoenix.db
    networks:
      - backend
    restart: always
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6006"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # BACKEND API
  backend-api:
    build:
      context: ./02-backend-api
      dockerfile: Dockerfile
    container_name: rag_backend_api
    ports:
      - "8000:8000"
    environment:
      
      - DB_CONNECTION_STRING=postgresql://postgres:postgres@pgvector:5432/rag_db
      - OLLAMA_BASE_URL=http://ollama:11434
      - PHOENIX_COLLECTOR_ENDPOINT=http://phoenix:6006/v1/traces
      - DEFAULT_LLM_MODEL=qwen2.5:0.5b
      - DEFAULT_EMBEDDING_MODEL=mxbai-embed-large:latest
      - FILE_ALLOWED_TYPES=pdf,docx,txt
      - FILE_MAX_SIZE=10485760
    depends_on:
      pgvector:
        condition: service_healthy
      ollama:
        condition: service_healthy
      phoenix:
        condition: service_healthy
    volumes:
      - ./02-backend-api:/app
      - ./assets:/app/assets
      - ./env:/app/env  # Share env files
    networks:
      - backend
    restart: unless-stopped

  # OPENWEBUI
  openwebui:
    image: ghcr.io/open-webui/open-webui:main-slim
    container_name: openwebui
    ports:
      - "3001:8080" 
    environment:
      # Connect OpenWebUI 
      - OPENAI_API_BASE_URL=http://backend-api:8000/v1
      - OPENAI_API_KEY=dummy-key-for-compatibility
      - WEBUI_NAME=Agentic RAG System
    depends_on:
      - backend-api
    volumes:
      - open-webui:/app/backend/data
    networks:
      - backend
    restart: always

# NETWORKS
networks:
  backend:
    driver: bridge

# VOLUMES
volumes:
  pgvector:
  open-webui:
  ollama_data: 